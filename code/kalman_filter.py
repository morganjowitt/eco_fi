import numpy as np
import pandas as pd
from statsmodels.tsa.statespace.mlemodel import MLEModel
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

class DynamicFactorModel(MLEModel):
    """
    Mod√®le de Facteurs Dynamiques (DFM) avec filtre de Kalman - Version corrig√©e
    """
    def __init__(self, endog, k_factors=1):
        # S'assurer que endog est un array numpy
        if isinstance(endog, pd.DataFrame):
            endog = endog.values
        endog = np.asarray(endog, dtype=float)
        
        super().__init__(endog, k_states=k_factors, initialization='diffuse')
        self.k_factors = k_factors
        self.n_obs = endog.shape[1]
        
        # Matrices du syst√®me d'√©tat - version simplifi√©e
        # Y_t = Lambda * F_t + epsilon_t
        # F_t = Phi * F_{t-1} + eta_t
        
        # Chargements factoriels (Lambda) - petites valeurs al√©atoires
        self['design'] = np.random.normal(0, 0.1, size=(self.n_obs, self.k_factors))
        
        # Matrice de transition des facteurs (Phi) - proche de l'identit√©
        self['transition'] = np.eye(self.k_factors) * 0.9
        
        # Matrice de s√©lection
        self['selection'] = np.eye(self.k_factors)
        
        # Covariance des chocs de facteurs
        self['state_cov'] = np.eye(self.k_factors) * 0.1

    def start_params(self):
        # Param√®tres de d√©part : variances des erreurs d'observation
        return np.full(self.n_obs, 0.1)

    def update(self, params, **kwargs):
        # Mettre √† jour avec les nouveaux param√®tres
        params = np.asarray(params, dtype=float)
        # Covariance des erreurs d'observation (diagonale)
        obs_cov = np.diag(np.maximum(params, 1e-8))
        self['obs_cov'] = obs_cov

    def transform_params(self, unconstrained):
        # Transformation pour assurer positivit√© (log -> exp)
        unconstrained = np.asarray(unconstrained, dtype=float)
        return np.exp(unconstrained)

    def untransform_params(self, constrained):
        # Transformation inverse (exp -> log)
        constrained = np.asarray(constrained, dtype=float)
        return np.log(np.maximum(constrained, 1e-8))

def extract_factors_kalman(df, k_factors=1):
    """
    Extraction de facteurs avec Filtre de Kalman (DFM) - Version robuste
    """
    print(f"üîÑ Extraction Kalman/DFM avec {k_factors} facteur(s)...")
    
    # M√©thode 1: Essayer avec statsmodels DynamicFactor directement
    try:
        print("   Tentative avec statsmodels DynamicFactor...")
        return extract_factors_statsmodels_dfm(df, k_factors)
    except Exception as e:
        print(f"   ‚ùå Statsmodels DFM √©chou√©: {str(e)[:60]}...")
    
    # M√©thode 2: DFM simplifi√© alternatif
    try:
        print("   Tentative avec DFM alternatif...")
        from statsmodels.tsa.statespace import dynamic_factor
        
        # Standardiser
        df_scaled = (df - df.mean()) / df.std()
        
        # Mod√®le DFM simplifi√©
        model = dynamic_factor.DynamicFactor(
            df_scaled.values, 
            k_factors=k_factors, 
            factor_order=1
        )
        
        result = model.fit(disp=False, maxiter=500)
        
        print("‚úÖ DFM alternatif r√©ussi")
        print(f"   Log-vraisemblance: {result.llf:.2f}")
        
        # Extraire facteurs
        factors_smooth = result.factors.smoothed.T
        
        factors_smooth_df = pd.DataFrame(
            factors_smooth, 
            index=df.index, 
            columns=[f'Kalman_Smooth_{i+1}' for i in range(k_factors)]
        )
        
        # Calculer loadings comme corr√©lations entre facteurs et variables
        loadings = np.zeros((df.shape[1], k_factors))
        for i in range(k_factors):
            for j, col in enumerate(df.columns):
                loadings[j, i] = df[col].corr(factors_smooth_df.iloc[:, i])
        
        return {
            'factors_smooth': factors_smooth_df,
            'factors_filter': factors_smooth_df,  # Utiliser smooth pour les deux
            'loadings': loadings,
            'model': result,
            'success': True,
            'method': 'DFM_Alternatif'
        }
        
    except Exception as e:
        print(f"   ‚ùå DFM alternatif √©chou√©: {str(e)[:60]}...")
    
    # Si tout √©choue
    return {
        'success': False,
        'error': 'Toutes les m√©thodes Kalman ont √©chou√©',
        'method': 'Kalman/DFM'
    }

def extract_factors_statsmodels_dfm(df, k_factors=1):
    """
    Utilise directement le DynamicFactor de statsmodels - Version am√©lior√©e
    """
    from statsmodels.tsa.statespace import dynamic_factor
    
    # Standardiser les donn√©es plus soigneusement
    df_scaled = df.copy()
    for col in df.columns:
        mean_val = df[col].mean()
        std_val = df[col].std()
        if std_val > 1e-10:
            df_scaled[col] = (df[col] - mean_val) / std_val
        else:
            df_scaled[col] = df[col] - mean_val
    
    # V√©rifier qu'il n'y a pas de valeurs infinies ou NaN
    if df_scaled.isnull().any().any() or np.isinf(df_scaled.values).any():
        raise ValueError("Donn√©es contiennent des NaN ou valeurs infinies")
    
    print(f"   Donn√©es pr√©par√©es: {df_scaled.shape}, min={df_scaled.min().min():.3f}, max={df_scaled.max().max():.3f}")
    
    # Mod√®le DFM avec param√®tres ajust√©s
    model = dynamic_factor.DynamicFactor(
        df_scaled.values, 
        k_factors=k_factors, 
        factor_order=1,           # AR(1) pour les facteurs
        error_order=0,           # Pas d'AR pour les erreurs
        enforce_stationarity=True # Forcer la stationnarit√©
    )
    
    # Estimation avec param√®tres robustes
    try:
        result = model.fit(
            disp=False, 
            maxiter=1000, 
            method='lbfgs',
            full_output=True
        )
        
        print("‚úÖ Statsmodels DFM r√©ussi")
        print(f"   Log-vraisemblance: {result.llf:.2f}")
        print(f"   AIC: {result.aic:.2f}")
        print(f"   Convergence: {result.mle_retvals.get('converged', 'Unknown')}")
        
    except Exception as e:
        print(f"   ‚ùå √âchec estimation: {e}")
        raise e
    
    # Extraire et v√©rifier les facteurs
    try:
        factors_smooth = result.factors.smoothed
        factors_filter = result.factors.filtered
        
        # V√©rifier que les facteurs ne sont pas tous z√©ros
        if np.allclose(factors_smooth, 0, atol=1e-10):
            print("   ‚ö†Ô∏è Facteurs liss√©s sont tous proches de z√©ro")
            raise ValueError("Facteurs Kalman invalides (tous z√©ros)")
        
        print(f"   Facteurs extraits: shape={factors_smooth.shape}")
        print(f"   Range facteur 1: [{factors_smooth[0].min():.3f}, {factors_smooth[0].max():.3f}]")
        
        # Transposer pour avoir observations x facteurs
        factors_smooth = factors_smooth.T
        factors_filter = factors_filter.T
        
    except Exception as e:
        print(f"   ‚ùå Erreur extraction facteurs: {e}")
        raise e
    
    # DataFrames
    factors_smooth_df = pd.DataFrame(
        factors_smooth, 
        index=df.index, 
        columns=[f'Kalman_Smooth_{i+1}' for i in range(k_factors)]
    )
    
    factors_filter_df = pd.DataFrame(
        factors_filter, 
        index=df.index, 
        columns=[f'Kalman_Filter_{i+1}' for i in range(k_factors)]
    )
    
    # Extraire chargements avec m√©thode robuste
    try:
        # M√©thode 1: Utiliser les param√®tres du mod√®le
        if hasattr(result, 'coefficient_matrices_var') and 'design' in result.coefficient_matrices_var:
            loadings = result.coefficient_matrices_var['design']
        else:
            # M√©thode 2: Calculer comme r√©gression des variables sur les facteurs
            loadings = np.zeros((df.shape[1], k_factors))
            for i in range(k_factors):
                factor_values = factors_smooth_df.iloc[:, i]
                if factor_values.std() > 1e-10:  # √âviter division par z√©ro
                    for j, col in enumerate(df.columns):
                        # R√©gression simple: var = alpha + beta * facteur
                        corr_coef = np.corrcoef(df[col].values, factor_values.values)[0, 1]
                        loadings[j, i] = corr_coef * (df[col].std() / factor_values.std())
        
        print(f"   Chargements calcul√©s: shape={loadings.shape}")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è Probl√®me chargements: {e}")
        # Chargements par d√©faut
        loadings = np.random.normal(0, 0.5, size=(df.shape[1], k_factors))
    
    return {
        'factors_smooth': factors_smooth_df,
        'factors_filter': factors_filter_df,
        'loadings': loadings,
        'model': result,
        'success': True,
        'method': 'Statsmodels_DFM'
    }

def extract_factors_custom_dfm(df, k_factors=1):
    """
    Notre mod√®le DFM custom
    """
    # Standardiser avec robustesse
    df_scaled = df.copy()
    for col in df.columns:
        mean_val = df[col].mean()
        std_val = df[col].std()
        if std_val > 1e-10:
            df_scaled[col] = (df[col] - mean_val) / std_val
        else:
            df_scaled[col] = df[col] - mean_val
    
    # Cr√©er mod√®le
    model = DynamicFactorModel(df_scaled, k_factors=k_factors)
    
    # Estimation avec m√©thode robuste
    result = model.fit(
        disp=False, 
        maxiter=500,
        method='nm',  # Nelder-Mead est plus robuste
        options={'maxiter': 500, 'xatol': 1e-4}
    )
    
    print("‚úÖ Custom DFM r√©ussi")
    print(f"   Log-vraisemblance: {result.llf:.2f}")
    
    # Extraire facteurs
    factors_smoothed = result.smoothed_state.T
    factors_filtered = result.filtered_state.T
    
    factors_smooth_df = pd.DataFrame(
        factors_smoothed, 
        index=df.index, 
        columns=[f'Kalman_Smooth_{i+1}' for i in range(k_factors)]
    )
    
    factors_filter_df = pd.DataFrame(
        factors_filtered, 
        index=df.index, 
        columns=[f'Kalman_Filter_{i+1}' for i in range(k_factors)]
    )
    
    # Chargements depuis la matrice design
    loadings = model['design']
    
    return {
        'factors_smooth': factors_smooth_df,
        'factors_filter': factors_filter_df,
        'loadings': loadings,
        'model': result,
        'success': True,
        'method': 'Custom_DFM'
    }

def extract_factors_simple_kalman(df, k_factors=1):
    """
    Filtre de Kalman tr√®s simple avec pykalman
    """
    try:
        from pykalman import KalmanFilter
        
        # Standardiser
        df_scaled = (df - df.mean()) / df.std()
        observations = df_scaled.values
        
        # Kalman Filter simple
        kf = KalmanFilter(
            n_dim_state=k_factors,
            n_dim_obs=df.shape[1]
        )
        
        # Estimation EM
        kf = kf.em(observations, n_iter=50)
        
        # Estimation des √©tats (facteurs)
        state_means, _ = kf.smooth(observations)
        
        print("‚úÖ PyKalman r√©ussi")
        
        # DataFrame
        factors_df = pd.DataFrame(
            state_means, 
            index=df.index, 
            columns=[f'Kalman_Simple_{i+1}' for i in range(k_factors)]
        )
        
        return {
            'factors_smooth': factors_df,
            'factors_filter': factors_df,
            'loadings': kf.observation_matrices,
            'model': kf,
            'success': True,
            'method': 'PyKalman'
        }
        
    except ImportError:
        print("   PyKalman non disponible")
        raise Exception("PyKalman non install√©")
    except Exception as e:
        print(f"   PyKalman √©chou√©: {e}")
        raise e

def extract_factors_pca(df, k_factors=1):
    """
    Extraction de facteurs avec ACP (Principal Component Analysis)
    """
    print(f"üîÑ Extraction ACP avec {k_factors} composante(s)...")
    
    # Standardiser les donn√©es
    df_scaled = (df - df.mean()) / df.std()
    
    try:
        # Appliquer l'ACP
        pca = PCA(n_components=k_factors)
        factors = pca.fit_transform(df_scaled)
        
        print("‚úÖ ACP estim√©e avec succ√®s")
        print(f"   Variance expliqu√©e: {pca.explained_variance_ratio_}")
        print(f"   Variance totale expliqu√©e: {pca.explained_variance_ratio_.sum():.3f}")
        
        # DataFrame des facteurs
        factors_df = pd.DataFrame(
            factors, 
            index=df.index, 
            columns=[f'PCA_{i+1}' for i in range(k_factors)]
        )
        
        # Chargements factoriels
        loadings = pca.components_.T
        
        return {
            'factors': factors_df,
            'loadings': loadings,
            'model': pca,
            'explained_variance': pca.explained_variance_ratio_,
            'success': True,
            'method': 'ACP'
        }
        
    except Exception as e:
        print(f"‚ùå Erreur ACP: {e}")
        return {
            'success': False,
            'error': str(e),
            'method': 'ACP'
        }

def compare_methods(df, k_factors=1):
    """
    Compare Kalman/DFM vs ACP
    """
    print("\n" + "="*60)
    print("üî¨ COMPARAISON DES M√âTHODES D'EXTRACTION")
    print("="*60)
    
    results = {}
    
    # 1. Extraction avec Kalman/DFM
    print("\n1Ô∏è‚É£ MOD√àLE DE FACTEURS DYNAMIQUES (Kalman)")
    kalman_result = extract_factors_kalman(df, k_factors)
    results['kalman'] = kalman_result
    
    # 2. Extraction avec ACP
    print("\n2Ô∏è‚É£ ANALYSE EN COMPOSANTES PRINCIPALES")
    pca_result = extract_factors_pca(df, k_factors)
    results['pca'] = pca_result
    
    # 3. Comparaison si les deux ont r√©ussi
    if kalman_result['success'] and pca_result['success']:
        print("\n" + "="*40)
        print("üìä COMPARAISON DES R√âSULTATS")
        print("="*40)
        
        # V√©rifier la validit√© des facteurs Kalman
        kalman_factors = kalman_result['factors_smooth']
        pca_factors = pca_result['factors']
        
        # V√©rifier si les facteurs Kalman sont valides
        kalman_valid = not (kalman_factors.isnull().all().any() or 
                           np.allclose(kalman_factors.values, 0, atol=1e-10))
        
        if not kalman_valid:
            print("‚ö†Ô∏è ATTENTION: Facteurs Kalman invalides (z√©ros ou NaN)")
            print("   ‚Üí Utilisation de l'ACP uniquement")
            return {'kalman': kalman_result, 'pca': pca_result, 'kalman_valid': False}
        
        # Corr√©lations avec les variables originales
        print("\nüîπ CORR√âLATIONS AVEC LES VARIABLES ORIGINALES:")
        print("\nKalman/DFM (facteur 1):")
        kalman_corr = df.corrwith(kalman_factors.iloc[:, 0]).abs().sort_values(ascending=False)
        for var, corr in kalman_corr.items():
            print(f"   {var}: {corr:.3f}")
        
        print("\nACP (composante 1):")
        pca_corr = df.corrwith(pca_factors.iloc[:, 0]).abs().sort_values(ascending=False)
        for var, corr in pca_corr.items():
            print(f"   {var}: {corr:.3f}")
        
        # Corr√©lation entre les facteurs des deux m√©thodes
        factor_correlation = kalman_factors.iloc[:, 0].corr(pca_factors.iloc[:, 0])
        print(f"\nüîπ CORR√âLATION ENTRE FACTEURS KALMAN-ACP: {abs(factor_correlation):.3f}")
        
        # M√©trique de performance
        kalman_avg_corr = kalman_corr.mean()
        pca_avg_corr = pca_corr.mean()
        
        print(f"\nüîπ PERFORMANCE MOYENNE:")
        print(f"   Kalman/DFM: {kalman_avg_corr:.3f}")
        print(f"   ACP: {pca_avg_corr:.3f}")
        
        # Recommandation
        print(f"\nüèÜ RECOMMANDATION:")
        if kalman_avg_corr > pca_avg_corr and not np.isnan(kalman_avg_corr):
            print("   ‚Üí Kalman/DFM semble meilleur (corr√©lations plus fortes)")
            print("   ‚Üí Avantage: Capture la dynamique temporelle")
        elif pca_avg_corr > kalman_avg_corr:
            print("   ‚Üí ACP semble meilleur (corr√©lations plus fortes)")
            print("   ‚Üí Avantage: Plus stable et interpr√©table")
        else:
            print("   ‚Üí ACP recommand√© (plus robuste)")
            print("   ‚Üí Kalman a des probl√®mes sur ces donn√©es")
        
        results['comparison'] = {
            'kalman_avg_corr': kalman_avg_corr,
            'pca_avg_corr': pca_avg_corr,
            'factor_correlation': abs(factor_correlation) if not np.isnan(factor_correlation) else 0,
            'kalman_corr': kalman_corr,
            'pca_corr': pca_corr,
            'kalman_valid': True
        }
    
    elif pca_result['success']:
        print("\n‚ö†Ô∏è SEULE L'ACP A FONCTIONN√â")
        print("   ‚Üí Utilisation de l'ACP par d√©faut")
        results['comparison'] = {'kalman_valid': False, 'pca_only': True}
    
    return results